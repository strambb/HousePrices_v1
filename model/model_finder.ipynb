{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal stuff\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "#special effects\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lars, ElasticNet, Lasso, LinearRegression, BayesianRidge, LassoLars\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1428, 101) (1459, 101) (1428,)\n"
    }
   ],
   "source": [
    "#Dataloader\n",
    "path =[r\"..\\data\\train_preprocessed.csv\", r\"..\\data\\test_preprocessed.csv\"]\n",
    "\n",
    "X = pd.read_csv(path[0])\n",
    "X_test = pd.read_csv(path[1], )\n",
    "\n",
    "y=X[\"logSalePrice\"]\n",
    "X.drop(\"logSalePrice\", axis=1, inplace=True)\n",
    "\n",
    "print(X.shape, X_test.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, train_size = 0.8, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n"
    }
   ],
   "source": [
    "#for c in X.columns:\n",
    "    #print(X[c].value_counts(dropna=False).sort_index())\n",
    "print(y_valid.isna().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation\n",
    "#Define a dict to store name and results per model for later evaluation \n",
    "Model_score_dict = {}\n",
    "#define a selected scaler\n",
    "selected_scaler = StandardScaler() #alternative: RobustScaler()\n",
    "#Models to choose:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base_Model\n",
    "#XGBR_final = XGBRegressor(n_estimators=4500, learning_rate=0.008, max_depth = 4, min_child_weight=4, gamma=0, subsample= 0.940136255964662, colsample_bytree = 0.5, alpha = 0.10925528556796542, early_stopping_counts=50, evals=y_valid, eval_metric=\"mae\",cv=True, seed=0, verbosity=1 )\n",
    "BaseReg = LinearRegression()\n",
    "\n",
    "my_pipe_out = Pipeline([#(\"preprocessing\", preprocessing),\n",
    "                        (\"selected_scaler\", selected_scaler),\n",
    "                        (\"basereg\", BaseReg)\n",
    "                        ])\n",
    "\n",
    "\n",
    "my_pipe_out.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "valid_preds = my_pipe_out.predict(X_valid)\n",
    "\n",
    "valid_score = mean_absolute_error(np.exp(y_valid), np.exp(valid_preds))\n",
    "#print(valid_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to choose from:\n",
    "* SVR\n",
    "* Ridge\n",
    "* Lasso\n",
    "* LassoLars\n",
    "* BayesianRidge\n",
    "* ElasticNet\n",
    "* RandomForestRegressor\n",
    "* AdaBoost\n",
    "* MLPRegressor\n",
    "* XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor SVR\n",
    "model_name= \"SVR\"\n",
    "finder_reg = SVR(C=10)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor Ridge\n",
    "model_name= \"Ridge\"\n",
    "finder_reg = Ridge(alpha = 0.5, random_state= 42)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Model constructor Lasso\n",
    "model_name= \"Lasso\"\n",
    "finder_reg = Lasso(alpha = 0.01, random_state= 42)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor LarsLasso\n",
    "model_name= \"LassoLars\"\n",
    "finder_reg = LassoLars(alpha=0.01)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor BayesianRidge\n",
    "model_name= \"BayesianRidge\"\n",
    "finder_reg = BayesianRidge()\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor ElasticNet\n",
    "model_name= \"ElasticNet\"\n",
    "finder_reg = ElasticNet(alpha=0.01)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor RandomForestRegressor\n",
    "model_name= \"RandomForestRegressor\"\n",
    "finder_reg = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor AdaBoostRegressor\n",
    "model_name= \"AdaBoost\"\n",
    "finder_reg = AdaBoostRegressor(n_estimators=100)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor MLPRegressor\n",
    "model_name= \"MLPRegressor\"\n",
    "finder_reg = MLPRegressor(learning_rate = \"adaptive\", hidden_layer_sizes=1000)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor Xgboost\n",
    "model_name = \"XGBR\"\n",
    "\n",
    "finder_reg = XGBRegressor(n_estimators = 2000, learning_rate=0.01)\n",
    "#XGBRegressor(n_estimators=4500, learning_rate=0.008, max_depth = 4, min_child_weight=4, gamma=0, subsample= 0.940136255964662, colsample_bytree = 0.5, alpha = 0.10925528556796542, early_stopping_counts=50, evals=y_valid, eval_metric=\"mae\",cv=True, seed=0, verbosity=1 )\n",
    "\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Base model: 13146.961\nFinder model: BayesianRidge \nBest Model Score: 13012.049 \nDifference total:-134.912\nDifference relative:-1.03%\n"
    }
   ],
   "source": [
    "#Finder and Search evaluation\n",
    "\n",
    "best_model = min(Model_score_dict.keys(), key=(lambda k : Model_score_dict[k]))\n",
    "best_score = Model_score_dict[best_model]\n",
    "model_diff_mae = Model_score_dict[best_model]-valid_score\n",
    "diff_rel_mae = model_diff_mae/valid_score*100\n",
    "print(f\"Base model: {valid_score:.3f}\\nFinder model: {best_model}\",\n",
    "f\"\\nBest Model Score: {best_score:.3f}\"\n",
    ",f\"\\nDifference total:{model_diff_mae:.3f}\\nDifference relative:{diff_rel_mae:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'SVR': 15834.916326726057, 'Ridge': 13165.488844408435, 'Lasso': 14021.591575077036, 'LassoLars': 53200.79878768031, 'BayesianRidge': 13012.048592358236, 'ElasticNet': 13338.56612697704, 'RandomForestRegressor': 16822.10147379778, 'AdaBoost': 20949.623115168142, 'MLPRegressor': 69042.70140661015, 'XGBR': 14290.888152862772}\n"
    }
   ],
   "source": [
    "print(Model_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OrderedDict([('reg__alpha', 0.0009921246613916195)])\n13008.586881846166\nOrderedDict([('reg__alpha_1', 0.0005937919697952091), ('reg__alpha_2', 9319.409005106054), ('reg__lambda_1', 4.351967422025814e-07), ('reg__lambda_2', 10.0), ('reg__n_iter', 1000)])\n13000.589026312135\nOrderedDict([('reg__alpha', 0.01724312576726878), ('reg__l1_ratio', 0.06658897509456764)])\n12938.577018190897\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   39.7s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   12.3s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   21.0s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   20.2s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   16.4s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   19.5s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   35.9s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:    0.9s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:    9.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   10.2s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _passthrough_scorer\n    return estimator.score(*args, **kwargs)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 116, in <lambda>\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 619, in score\n    return self.steps[-1][-1].score(Xt, y, **score_params)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 424, in score\n    y_type, _, _, _ = _check_reg_targets(y, y_pred, None)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 86, in _check_reg_targets\n    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 578, in check_array\n    allow_nan=force_all_finite == 'allow-nan')\n  File \"D:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 60, in _assert_all_finite\n    msg_dtype if msg_dtype is not None else X.dtype)\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-404983217b56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_search_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[0msearch_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0msearch_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[0;32m    678\u001b[0m                 optim_result = self._step(\n\u001b[0;32m    679\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m                     \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m                 )\n\u001b[0;32m    682\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             )\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m             for train, test in cv_iter)\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "#GridSearchCV Top5 \n",
    "\n",
    "cv = 5\n",
    "\n",
    "#Lasso\n",
    "search_reg = Lasso(random_state=42,)\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  \"reg__alpha\": Real(0.0001, 1, \"log-uniform\")#[0.003914914914914915],\n",
    "                }\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=0, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2,random_state=42)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search_score)\n",
    "\n",
    "#BayesianRidge\n",
    "search_reg = BayesianRidge()\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  \"reg__n_iter\":(100,1000),#[0.003914914914914915],\n",
    "                \"reg__alpha_1\":(1e-7, 1e+1,\"log-uniform\"),\n",
    "                \"reg__alpha_2\":(1e-7, 1e+10,\"log-uniform\"),\n",
    "                \"reg__lambda_1\":(1e-7, 1e+1,\"log-uniform\"),\n",
    "                \"reg__lambda_2\":(1e-7, 1e+1,\"log-uniform\"),\n",
    "                }\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2,random_state=42)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search_score)\n",
    "\n",
    "#Elastic net:\n",
    "search_reg = ElasticNet(random_state=42)\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  \"reg__alpha\": Real( 0.001, 0.018),#[0.01]0.016387841323033663\n",
    "                \"reg__l1_ratio\": Real(0.0001, 0.095)  #[0.38612244897959186]0.21582216780480853\n",
    "                }\n",
    "\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=0, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2, random_state=42)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search_score)\n",
    "\n",
    "\n",
    "#XGB:\n",
    "search_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": [31],\n",
    "                \"reg__early_stopping_counts\": [10],\n",
    "                \"reg__n_estimators\": Integer(100, 10000),\n",
    "                \"reg__learning_rate\":Real(1e-7, 1e+1, \"log-uniform\"),\n",
    "                \"reg__max_depth\": Integer(1, 15),\n",
    "                \"reg__min_child_weight\":Integer(1,15), #done range(1,15,1)\n",
    "                \"reg__gamma\":[0], #done [ 0, 1, 5],\n",
    "                \"reg__subsample\":Real(0.1,0.9),#[0.940136255964662][0.3283798423145866]\n",
    "                \"reg__colsample_bytree\": Real(0.1,0.9),#[i/100.0 for i in range(45,55,1)], \n",
    "                \"reg__alpha\":Real(0.1,0.9),\n",
    "}\n",
    "\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=0, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2, random_state=42, verbose=1)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_preds = my_pipe_out.predict(X_test)\n",
    "\n",
    "#recalc preds\n",
    "test_preds=np.exp(test_preds)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({\"Id\": X_test.index,\n",
    "                     \"SalePrice\": test_preds})\n",
    "output.to_csv(r\"..\\output\\submission_other.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "14242\n",
    "\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": [31],\n",
    "                \"reg__early_stopping_counts\": [10],\n",
    "                \"reg__n_estimators\": [1000],\n",
    "                \"reg__learning_rate\":[0.1],\n",
    "                \"reg__max_depth\": [1], #done[1, 2, 3, 4, 5, 6],\n",
    "                \"reg__min_child_weight\":[12], #done range(1,15,1)\n",
    "                \"reg__gamma\":[0], #done [ 0, 1, 5],\n",
    "                \"reg__subsample\":np.linspace(0.59, .62, 100),#[0.940136255964662][0.3283798423145866]\n",
    "                \"reg__colsample_bytree\": [0.5],#[i/100.0 for i in range(45,55,1)], \n",
    "                \"reg__alpha\":[0.10925528556796542],\n",
    "                \n",
    "                }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbaseconda89a626014d0c491794506a11735c5634",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}