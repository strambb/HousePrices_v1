{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal stuff\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "#special effects\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lars, ElasticNet, Lasso, LinearRegression, BayesianRidge, LassoLars\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1428, 92) (1459, 92) (1428,)\n"
    }
   ],
   "source": [
    "#Dataloader\n",
    "path =[r\"..\\data\\train_preprocessed.csv\", r\"..\\data\\test_preprocessed.csv\"]\n",
    "\n",
    "X = pd.read_csv(path[0])\n",
    "X_test = pd.read_csv(path[1], )\n",
    "\n",
    "y=X[\"logSalePrice\"]\n",
    "X.drop(\"logSalePrice\", axis=1, inplace=True)\n",
    "\n",
    "print(X.shape, X_test.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, train_size = 0.8, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n"
    }
   ],
   "source": [
    "#for c in X.columns:\n",
    "    #print(X[c].value_counts(dropna=False).sort_index())\n",
    "print(y_valid.isna().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation\n",
    "#Define a dict to store name and results per model for later evaluation \n",
    "Model_score_dict = {}\n",
    "#define a selected scaler\n",
    "selected_scaler = StandardScaler() #alternative: RobustScaler()\n",
    "#Models to choose:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base_Model\n",
    "#XGBR_final = XGBRegressor(n_estimators=4500, learning_rate=0.008, max_depth = 4, min_child_weight=4, gamma=0, subsample= 0.940136255964662, colsample_bytree = 0.5, alpha = 0.10925528556796542, early_stopping_counts=50, evals=y_valid, eval_metric=\"mae\",cv=True, seed=0, verbosity=1 )\n",
    "BaseReg = LinearRegression()\n",
    "\n",
    "my_pipe_out = Pipeline([#(\"preprocessing\", preprocessing),\n",
    "                        (\"selected_scaler\", selected_scaler),\n",
    "                        (\"basereg\", BaseReg)\n",
    "                        ])\n",
    "\n",
    "\n",
    "my_pipe_out.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "valid_preds = my_pipe_out.predict(X_valid)\n",
    "\n",
    "valid_score = mean_absolute_error(np.exp(y_valid), np.exp(valid_preds))\n",
    "#print(valid_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to choose from:\n",
    "* SVR\n",
    "* Ridge\n",
    "* Lasso\n",
    "* LassoLars\n",
    "* BayesianRidge\n",
    "* ElasticNet\n",
    "* RandomForestRegressor\n",
    "* AdaBoost\n",
    "* MLPRegressor\n",
    "* XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor SVR\n",
    "model_name= \"SVR\"\n",
    "finder_reg = SVR(C=10)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor Ridge\n",
    "model_name= \"Ridge\"\n",
    "finder_reg = Ridge(alpha = 0.5, random_state= 42)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Model constructor Lasso\n",
    "model_name= \"Lasso\"\n",
    "finder_reg = Lasso(alpha = 0.01, random_state= 42)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor LarsLasso\n",
    "model_name= \"LassoLars\"\n",
    "finder_reg = LassoLars(alpha=0.01)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor BayesianRidge\n",
    "model_name= \"BayesianRidge\"\n",
    "finder_reg = BayesianRidge()\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor ElasticNet\n",
    "model_name= \"ElasticNet\"\n",
    "finder_reg = ElasticNet(alpha=0.01)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor RandomForestRegressor\n",
    "model_name= \"RandomForestRegressor\"\n",
    "finder_reg = RandomForestRegressor(n_estimators=500)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor AdaBoostRegressor\n",
    "model_name= \"AdaBoost\"\n",
    "finder_reg = AdaBoostRegressor(n_estimators=100)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor MLPRegressor\n",
    "model_name= \"MLPRegressor\"\n",
    "finder_reg = MLPRegressor(learning_rate = \"adaptive\", hidden_layer_sizes=1000)\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constructor Xgboost\n",
    "model_name = \"XGBR\"\n",
    "\n",
    "finder_reg = XGBRegressor(n_estimators = 2000, learning_rate=0.01)\n",
    "#XGBRegressor(n_estimators=4500, learning_rate=0.008, max_depth = 4, min_child_weight=4, gamma=0, subsample= 0.940136255964662, colsample_bytree = 0.5, alpha = 0.10925528556796542, early_stopping_counts=50, evals=y_valid, eval_metric=\"mae\",cv=True, seed=0, verbosity=1 )\n",
    "\n",
    "\n",
    "finder_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"finder_reg\", finder_reg)\n",
    "                        ])\n",
    "\n",
    "finder_pipe.fit(X_train, y_train)\n",
    "finder_valid_preds = finder_pipe.predict(X_valid)\n",
    "finder_valid_score = mean_absolute_error(np.exp(y_valid), np.exp(finder_valid_preds))\n",
    "Model_score_dict[model_name] = finder_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Base model: 12960.034\nFinder model: BayesianRidge \nBest Model Score: 12772.596 \nDifference total:-187.438\nDifference relative:-1.45%\n"
    }
   ],
   "source": [
    "#Finder and Search evaluation\n",
    "\n",
    "best_model = min(Model_score_dict.keys(), key=(lambda k : Model_score_dict[k]))\n",
    "best_score = Model_score_dict[best_model]\n",
    "model_diff_mae = Model_score_dict[best_model]-valid_score\n",
    "diff_rel_mae = model_diff_mae/valid_score*100\n",
    "print(f\"Base model: {valid_score:.3f}\\nFinder model: {best_model}\",\n",
    "f\"\\nBest Model Score: {best_score:.3f}\"\n",
    ",f\"\\nDifference total:{model_diff_mae:.3f}\\nDifference relative:{diff_rel_mae:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'SVR': 15424.29933599959, 'Ridge': 12954.28074534343, 'Lasso': 14014.716771812364, 'LassoLars': 53200.79878768031, 'BayesianRidge': 12772.595959479322, 'ElasticNet': 13258.743232581914, 'RandomForestRegressor': 16458.219994595493, 'AdaBoost': 20363.59218076854, 'MLPRegressor': 69341.31393217665, 'XGBR': 14327.31905594406}\n"
    }
   ],
   "source": [
    "print(Model_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OrderedDict([('reg__alpha', 0.003512976943090333)])\n-0.07898295681888984 12998.669473693668\nOrderedDict([('reg__alpha_1', 10.0), ('reg__alpha_2', 0.01), ('reg__lambda_1', 10897.323189172308), ('reg__lambda_2', 1.7949357919759679), ('reg__n_iter', 559)])\n-0.0791889349208608 12779.920613523722\n[nan nan nan nan nan]\nOrderedDict([('reg__alpha', 0.02), ('reg__l1_ratio', 0.06)])\n-0.0789022988699991 12817.02885729466\n"
    }
   ],
   "source": [
    "#GridSearchCV Top5 \n",
    "\n",
    "cv = 5\n",
    "\n",
    "#Lasso\n",
    "search_reg = Lasso(random_state=42,)\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  \"reg__alpha\": Real(0.0001, 1, \"log-uniform\")#[0.003914914914914915],\n",
    "                }\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=0, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2,random_state=42, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_,search_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BayesianRidge\n",
    "search_reg = BayesianRidge()\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  \"reg__n_iter\":(100,1000),#[0.003914914914914915],\n",
    "                \"reg__alpha_1\":(1e-6, 1e+1,\"log-uniform\"),\n",
    "                \"reg__alpha_2\":(1e-2, 1e+10,\"log-uniform\"),\n",
    "                \"reg__lambda_1\":(1e-6, 1e+10,\"log-uniform\"),\n",
    "                \"reg__lambda_2\":(1e-6, 1e+1,\"log-uniform\"),\n",
    "                }\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2,random_state=42, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_,search_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.09209944315752616\nOrderedDict([('reg__alpha', 0.04690935629679825), ('reg__l1_ratio', 0.05366354459063951)])\n-0.07861650345909034 12960.689899247132\n"
    }
   ],
   "source": [
    "#Elastic net:\n",
    "search_reg = ElasticNet(random_state=42)\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  \"reg__alpha\": Real( 0.01, 0.1),#[0.01]0.016387841323033663\n",
    "                \"reg__l1_ratio\": Real(0.01, 0.07)  #[0.38612244897959186]0.21582216780480853\n",
    "                }\n",
    "\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=0, n_jobs=-2, cv = cv,)\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2, random_state=42, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "\n",
    "print(-cross_val_score(eln_cv, X=X_valid,y= y_valid, scoring=\"neg_mean_absolute_error\", cv = 20).mean())\n",
    "print(search.best_params_)\n",
    "print(search.best_score_, search_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'alpha': 0.02, 'l1_ratio': 0.06}\n0.09209944315752616\n"
    }
   ],
   "source": [
    "\n",
    "print(dict(zip([\"alpha\", \"l1_ratio\"], search.best_params_.values())))\n",
    "eln_cv=ElasticNet(alpha=search.best_params_[\"reg__alpha\"], l1_ratio=search.best_params_[\"reg__l1_ratio\"])\n",
    "print(-cross_val_score(eln_cv, X=X_valid,y= y_valid, scoring=\"neg_mean_absolute_error\", cv = 20).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   28.8s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   22.6s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   21.8s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   33.2s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   26.7s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   31.0s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   40.8s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   37.8s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   14.5s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   25.6s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   37.9s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   39.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   43.0s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   14.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   50.5s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:  1.0min finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   39.6s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   15.5s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   49.6s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   14.6s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   46.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   47.2s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   13.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   39.5s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   56.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   53.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   37.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   12.4s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   45.6s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   46.4s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   43.5s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   56.2s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   57.9s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   13.5s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   47.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   45.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   45.4s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   14.9s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   36.3s finished\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   35.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   47.4s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   29.2s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   30.8s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   38.6s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   36.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   41.9s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   26.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   35.3s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   28.7s finished\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   37.8s finished\nOrderedDict([('reg__alpha', 2.6274078830082574e-07), ('reg__colsample_bytree', 0.5356793939292311), ('reg__early_stopping_counts', 25), ('reg__gamma', 0), ('reg__lambda', 4.251721413217407), ('reg__learning_rate', 0.003663102785875358), ('reg__max_depth', 5), ('reg__min_child_weight', 10), ('reg__n_estimators', 6000), ('reg__subsample', 0.5047660450529343)])\n-0.07906265397105035\n13914.139600633747\n"
    }
   ],
   "source": [
    "#XGB:\n",
    "search_reg = XGBRegressor(eval=y_valid, eval_metric=\"mae\")\n",
    "\n",
    "my_search_pipe = Pipeline([(\"scaler\", selected_scaler),\n",
    "                        (\"reg\", search_reg)\n",
    "                        ])\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": [31],\n",
    "                \"reg__early_stopping_counts\": [25],\n",
    "                \"reg__n_estimators\": [6000],\n",
    "                \"reg__learning_rate\":[0.003663102785875358],\n",
    "                \"reg__max_depth\": Integer(1,8),\n",
    "                \"reg__min_child_weight\":Integer(1,10), #done range(1,15,1)\n",
    "                \"reg__gamma\":[0], #done [ 0, 1, 5],\n",
    "                \"reg__subsample\":Real(0.5,0.95),#[0.940136255964662][0.3283798423145866]\n",
    "                \"reg__colsample_bytree\": Real(0.5,0.8),#[i/100.0 for i in range(45,55,1)], \n",
    "                \"reg__alpha\":Real(1e-7,1e-1, \"log-uniform\"),\n",
    "                \"reg__lambda\": Real(1, 10)\n",
    "}\n",
    "\n",
    "\n",
    "#search = GridSearchCV(my_search_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=0, n_jobs=-2, cv = cv,)\n",
    "\n",
    "search = BayesSearchCV(my_search_pipe, param_grid, n_iter=50, n_jobs=-2, random_state=42, verbose=1,scoring=\"neg_mean_absolute_error\")\n",
    "search.fit(X_train,y_train)\n",
    "\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-0.0789022988699991"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_preds = my_pipe_out.predict(X_test)\n",
    "\n",
    "#recalc preds\n",
    "test_preds=np.exp(test_preds)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({\"Id\": X_test.index,\n",
    "                     \"SalePrice\": test_preds})\n",
    "output.to_csv(r\"..\\output\\submission_other.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "14242\n",
    "\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": [31],\n",
    "                \"reg__early_stopping_counts\": [10],\n",
    "                \"reg__n_estimators\": [1000],\n",
    "                \"reg__learning_rate\":[0.1],\n",
    "                \"reg__max_depth\": [1], #done[1, 2, 3, 4, 5, 6],\n",
    "                \"reg__min_child_weight\":[12], #done range(1,15,1)\n",
    "                \"reg__gamma\":[0], #done [ 0, 1, 5],\n",
    "                \"reg__subsample\":np.linspace(0.59, .62, 100),#[0.940136255964662][0.3283798423145866]\n",
    "                \"reg__colsample_bytree\": [0.5],#[i/100.0 for i in range(45,55,1)], \n",
    "                \"reg__alpha\":[0.10925528556796542],\n",
    "                \n",
    "                }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbaseconda89a626014d0c491794506a11735c5634",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}