{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdsproj10320conda7d2d0b8284c34340aa156a3daf2ddb47",
   "display_name": "Python 3.7.6 64-bit ('DS_proj1_03-20': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Notebook\n",
    "## Module Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis (General)\n",
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"data\\train.csv\"\n",
    "X_raw = pd.read_csv(path, index_col=\"Id\")\n",
    "X_test = pd.read_csv(path, index_col =\"Id\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\nId                                                                    \n1           60       RL         65.0     8450   Pave   NaN      Reg   \n2           20       RL         80.0     9600   Pave   NaN      Reg   \n3           60       RL         68.0    11250   Pave   NaN      IR1   \n4           70       RL         60.0     9550   Pave   NaN      IR1   \n5           60       RL         84.0    14260   Pave   NaN      IR1   \n\n   LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\nId                                  ...                                     \n1          Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n2          Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n3          Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n4          Lvl    AllPub    Corner  ...           0        0    NaN   NaN   \n5          Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n\n   MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \nId                                                               \n1          NaN       0       2    2008        WD         Normal  \n2          NaN       0       5    2007        WD         Normal  \n3          NaN       0       9    2008        WD         Normal  \n4          NaN       0       2    2006        WD        Abnorml  \n5          NaN       0      12    2008        WD         Normal  \n\n[5 rows x 79 columns]\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1460 entries, 1 to 1460\nData columns (total 79 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   MSSubClass     1460 non-null   int64  \n 1   MSZoning       1460 non-null   object \n 2   LotFrontage    1201 non-null   float64\n 3   LotArea        1460 non-null   int64  \n 4   Street         1460 non-null   object \n 5   Alley          91 non-null     object \n 6   LotShape       1460 non-null   object \n 7   LandContour    1460 non-null   object \n 8   Utilities      1460 non-null   object \n 9   LotConfig      1460 non-null   object \n 10  LandSlope      1460 non-null   object \n 11  Neighborhood   1460 non-null   object \n 12  Condition1     1460 non-null   object \n 13  Condition2     1460 non-null   object \n 14  BldgType       1460 non-null   object \n 15  HouseStyle     1460 non-null   object \n 16  OverallQual    1460 non-null   int64  \n 17  OverallCond    1460 non-null   int64  \n 18  YearBuilt      1460 non-null   int64  \n 19  YearRemodAdd   1460 non-null   int64  \n 20  RoofStyle      1460 non-null   object \n 21  RoofMatl       1460 non-null   object \n 22  Exterior1st    1460 non-null   object \n 23  Exterior2nd    1460 non-null   object \n 24  MasVnrType     1452 non-null   object \n 25  MasVnrArea     1452 non-null   float64\n 26  ExterQual      1460 non-null   object \n 27  ExterCond      1460 non-null   object \n 28  Foundation     1460 non-null   object \n 29  BsmtQual       1423 non-null   object \n 30  BsmtCond       1423 non-null   object \n 31  BsmtExposure   1422 non-null   object \n 32  BsmtFinType1   1423 non-null   object \n 33  BsmtFinSF1     1460 non-null   int64  \n 34  BsmtFinType2   1422 non-null   object \n 35  BsmtFinSF2     1460 non-null   int64  \n 36  BsmtUnfSF      1460 non-null   int64  \n 37  TotalBsmtSF    1460 non-null   int64  \n 38  Heating        1460 non-null   object \n 39  HeatingQC      1460 non-null   object \n 40  CentralAir     1460 non-null   object \n 41  Electrical     1459 non-null   object \n 42  1stFlrSF       1460 non-null   int64  \n 43  2ndFlrSF       1460 non-null   int64  \n 44  LowQualFinSF   1460 non-null   int64  \n 45  GrLivArea      1460 non-null   int64  \n 46  BsmtFullBath   1460 non-null   int64  \n 47  BsmtHalfBath   1460 non-null   int64  \n 48  FullBath       1460 non-null   int64  \n 49  HalfBath       1460 non-null   int64  \n 50  BedroomAbvGr   1460 non-null   int64  \n 51  KitchenAbvGr   1460 non-null   int64  \n 52  KitchenQual    1460 non-null   object \n 53  TotRmsAbvGrd   1460 non-null   int64  \n 54  Functional     1460 non-null   object \n 55  Fireplaces     1460 non-null   int64  \n 56  FireplaceQu    770 non-null    object \n 57  GarageType     1379 non-null   object \n 58  GarageYrBlt    1379 non-null   float64\n 59  GarageFinish   1379 non-null   object \n 60  GarageCars     1460 non-null   int64  \n 61  GarageArea     1460 non-null   int64  \n 62  GarageQual     1379 non-null   object \n 63  GarageCond     1379 non-null   object \n 64  PavedDrive     1460 non-null   object \n 65  WoodDeckSF     1460 non-null   int64  \n 66  OpenPorchSF    1460 non-null   int64  \n 67  EnclosedPorch  1460 non-null   int64  \n 68  3SsnPorch      1460 non-null   int64  \n 69  ScreenPorch    1460 non-null   int64  \n 70  PoolArea       1460 non-null   int64  \n 71  PoolQC         7 non-null      object \n 72  Fence          281 non-null    object \n 73  MiscFeature    54 non-null     object \n 74  MiscVal        1460 non-null   int64  \n 75  MoSold         1460 non-null   int64  \n 76  YrSold         1460 non-null   int64  \n 77  SaleType       1460 non-null   object \n 78  SaleCondition  1460 non-null   object \ndtypes: float64(3), int64(33), object(43)\nmemory usage: 912.5+ KB\nNone\n        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\ncount  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \nmean     56.897260    70.049958   10516.828082     6.099315     5.575342   \nstd      42.300571    24.284752    9981.264932     1.382997     1.112799   \nmin      20.000000    21.000000    1300.000000     1.000000     1.000000   \n25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \nmax     190.000000   313.000000  215245.000000    10.000000     9.000000   \n\n         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\ncount  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \nmean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \nstd      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \nmin    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \nmax    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n\n        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\ncount  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \nmean    472.980137    94.244521    46.660274      21.954110     3.409589   \nstd     213.804841   125.338794    66.256028      61.119149    29.317331   \nmin       0.000000     0.000000     0.000000       0.000000     0.000000   \n25%     334.500000     0.000000     0.000000       0.000000     0.000000   \n50%     480.000000     0.000000    25.000000       0.000000     0.000000   \n75%     576.000000   168.000000    68.000000       0.000000     0.000000   \nmax    1418.000000   857.000000   547.000000     552.000000   508.000000   \n\n       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \ncount  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000  \nmean     15.060959     2.758904     43.489041     6.321918  2007.815753  \nstd      55.757415    40.177307    496.123024     2.703626     1.328095  \nmin       0.000000     0.000000      0.000000     1.000000  2006.000000  \n25%       0.000000     0.000000      0.000000     5.000000  2007.000000  \n50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \nmax     480.000000   738.000000  15500.000000    12.000000  2010.000000  \n\n[8 rows x 36 columns]\nSummary:\n\nNumber of columns: 79\nNumber of object columns: 43\nNumber of columns with NaNs: 19\nNumber of object columns with NaNs: 16\nNumber of numeric columns with NaNs: 3\n"
    }
   ],
   "source": [
    "X = X_raw.copy()\n",
    "X.dropna(subset=[\"SalePrice\"], axis=0, inplace=True)\n",
    "#X.dropna(axis=1, inplace = True)\n",
    "y = X.SalePrice\n",
    "X.drop(\"SalePrice\", axis=1, inplace=True)\n",
    "\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "print(X.describe())\n",
    "\n",
    "col_obj = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "col_obj_above_10 = list([col for col in col_obj if X[col].nunique() > 15])\n",
    "col_obj_below_10 = list(set(col_obj)-set(col_obj_above_10))\n",
    "col_num = X.select_dtypes(exclude=[\"object\", \"bool\"]).columns.values\n",
    "col_with_nan = [col for col in X.columns if X[col].isna().any()]\n",
    "\n",
    "\n",
    "print(\"Summary:\\n\")\n",
    "print(\"Number of columns: {}\".format(len(X.columns)))\n",
    "print(\"Number of object columns: {}\".format(len(col_obj)))\n",
    "print(\"Number of columns with NaNs: {}\".format(len(col_with_nan)))\n",
    "print(\"Number of object columns with NaNs: {}\".format(len(set(col_with_nan)-set(col_num))))\n",
    "print(\"Number of numeric columns with NaNs: {}\".format(len(set(col_with_nan)-set(col_obj))))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lars, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= {}\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:    4.7s\n[Parallel(n_jobs=-2)]: Done  11 tasks      | elapsed:    9.6s\n[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:   14.3s\n[Parallel(n_jobs=-2)]: Done  27 tasks      | elapsed:   19.2s\n[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:   28.6s\n[Parallel(n_jobs=-2)]: Done  47 tasks      | elapsed:   33.6s\n[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:   42.8s\n[Parallel(n_jobs=-2)]: Done  71 tasks      | elapsed:   52.5s\n[Parallel(n_jobs=-2)]: Done  84 tasks      | elapsed:   58.3s\n[Parallel(n_jobs=-2)]: Done  98 out of 100 | elapsed:  1.1min remaining:    1.3s\n[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:  1.2min finished\n15075.204376601989\n{'reg__alpha': 0.107, 'reg__colsample_bytree': 0.551988011711525, 'reg__early_stopping_counts': 50, 'reg__gamma': 0, 'reg__learning_rate': 0.04002371183530562, 'reg__max_depth': 5, 'reg__min_child_weight': 1.02, 'reg__n_estimators': 342, 'reg__subsample': 0.8264488486588846}\n"
    }
   ],
   "source": [
    "\n",
    "#reg = ElasticNet()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, train_size = 0.8, test_size=0.2, random_state=0)\n",
    "reg = XGBRegressor(evals=([X_valid, y_valid]), eval_metric=\"mae\", cv=True, seed=0 )\n",
    "\n",
    "\n",
    "#numeric_transformer = Pipeline([\"imputer\",SimpleImputer(strategy=\"median\")])\n",
    "\n",
    "\n",
    "\n",
    "#raising value error due to lack in synchronization caused by OneHotEncoder and OrdinalEncoder\n",
    "preprocessing = ColumnTransformer(transformers=[(\"numeric\", SimpleImputer(strategy = \"median\"), col_num) ,\n",
    "                                            (\"obj_below_10\", Pipeline([(\"obj_imputer1\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"OHE\"            , OneHotEncoder(handle_unknown='ignore'\n",
    "                                                                                                            ))\n",
    "                                                                        ]), col_obj_below_10) ,\n",
    "                                            (\"Neighborhood_\", Pipeline([(\"obj_imputer2\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder\"  , OrdinalEncoder(categories=[list(X[\"Neighborhood\"].unique())])\n",
    "                                                                                                            )\n",
    "                                                                        ]), [\"Neighborhood\"]),\n",
    "                                            (\"Exterior_2nd\", Pipeline([(\"obj_imputer2\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder\"  , OrdinalEncoder(categories=[list(X[\"Exterior2nd\"].unique())]))\n",
    "                                                                        ]), [\"Exterior2nd\"])], remainder='drop')\n",
    "\n",
    "\n",
    "my_pipe = Pipeline([(\"preprocessing\",preprocessing),\n",
    "                     #(\"pca\", PCA(n_components = 35)),\n",
    "                     (\"std_scaler\", StandardScaler()),\n",
    "                     (\"reg\",reg)])\n",
    "\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": np.linspace(25, 65, 5, dtype=\"int\"),\n",
    "                \"reg__early_stopping_counts\": [50],\n",
    "                \"reg__n_estimators\": [342],\n",
    "                \"reg__learning_rate\":[0.04002371183530562],\n",
    "                \"reg__max_depth\": [5],\n",
    "                \"reg__min_child_weight\": [1.02],\n",
    "                \"reg__gamma\":[0],\n",
    "                \"reg__subsample\":[0.8264488486588846],\n",
    "                \"reg__colsample_bytree\": [0.551988011711525],\n",
    "                \"reg__alpha\":[0.107],\n",
    "                \n",
    "                }\n",
    "cv = 5\n",
    "\n",
    "search = GridSearchCV(my_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=10, n_jobs=-2, cv = cv, return_train_score=True)\n",
    "search.fit(X_train,y_train)\n",
    "print(abs(search.best_score_))\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(y_valid, search_pred)\n",
    "print(search.best_params_)\n",
    "\n",
    "res[search.best_score_] = search.best_params_\n",
    "\n",
    "test_preds = search.predict(X_test)\n",
    "output = pd.DataFrame({\"Id\": X_test.index,\n",
    "                     \"SalePrice\": test_preds})\n",
    "output.to_csv(\"submission_other.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.82613313 0.82735801 0.8259717  0.82848889 0.82520206 0.82477332\n 0.82488329 0.82564345 0.82541489 0.82849009 0.82620751 0.82519133\n 0.82764839 0.82594748 0.82529715 0.82740985 0.82715737 0.82609905\n 0.82794155 0.82666311]\n"
    }
   ],
   "source": [
    "subsample= 0.8265340078198108\n",
    "subsample=0.8264608951160635\n",
    "subsample_best = 0.8264488486588846\n",
    "colsample_0 = 0.5519746590351778\n",
    "colsample_best= 0.551988011711525\n",
    "n_est = 349\n",
    "n_est = 343\n",
    "print(np.random.normal(0.8265340078198108, 0.001, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.56164268, 0.39845238, 0.63052302, 0.51357658, 0.56442523,\n       0.67122589, 0.57949522, 0.57726715, 0.57867034, 0.47769325,\n       0.63462088, 0.70535632, 0.62690097, 0.63951129, 0.46329226,\n       0.46424169, 0.40693281, 0.67424572, 0.52560242, 0.6910048 ])"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "np.random.normal(0.5510204081632653, 0.1,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Choose a relatively high learning rate. Generally a learning rate of 0.1 works but somewhere between 0.05 to 0.3 should work for different problems. Determine the optimum number of trees for this learning rate. XGBoost has a very useful function called as “cv” which performs cross-validation at each boosting iteration and thus returns the optimum number of trees required.\n",
    "Tune tree-specific parameters ( max_depth, min_child_weight, gamma, subsample, colsample_bytree) for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "Tune regularization parameters (lambda, alpha) for xgboost which can help reduce model complexity and enhance performance.\n",
    "Lower the learning rate and decide the optimal parameters .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.compose import Tar\n",
    "\n",
    "#reg = XGBRegressor(early_stopping_counts=5, eval_stop=([X_valid, y_valid]) )\n",
    "reg = ElasticNet()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, train_size = 0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "#numeric_transformer = Pipeline([\"imputer\",SimpleImputer(strategy=\"median\")])\n",
    "\n",
    "\n",
    "\n",
    "#raising value error due to lack in synchronization caused by OneHotEncoder and OrdinalEncoder\n",
    "preprocessing = ColumnTransformer(transformers=[(\"numeric\", SimpleImputer(strategy = \"median\"), col_num) ,\n",
    "                                            (\"obj_below_10\", Pipeline([(\"obj_imputer1\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"OHE\"            , OneHotEncoder(handle_unknown='ignore'\n",
    "                                                                                                            ))\n",
    "                                                                        ]), col_obj_below_10) ,\n",
    "                                            (\"Neighborhood_\", Pipeline([(\"obj_imputer2\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder\"  , OrdinalEncoder(categories=[list(X[\"Neighborhood\"].unique())])\n",
    "                                                                                                            )\n",
    "                                                                        ]), [\"Neighborhood\"]),\n",
    "                                            (\"Exterior_2nd\", Pipeline([(\"obj_imputer2\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder\"  , OrdinalEncoder(categories=[list(X[\"Exterior2nd\"].unique())]))\n",
    "                                                                        ]), [\"Exterior2nd\"])], remainder='drop')\n",
    "\n",
    "\n",
    "my_pipe = Pipeline([(\"preprocessing\",preprocessing),\n",
    "                     (\"pca\", PCA(n_components = 42)),\n",
    "                     (\"reg\",reg)])\n",
    "\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                \"pca__n_components\": np.linspace(25, 65, 10, dtype=\"int\"),\n",
    "                #\"reg__n_estimators\": np.linspace(100, 1000, 20, dtype=\"int\"),\n",
    "                \"reg__alpha\":np.linspace(.01,1.5,50),\n",
    "                \"reg__l1_ratio\": np.linspace(.2, .8, 10)\n",
    "                }\n",
    "cv = 5\n",
    "\n",
    "search = GridSearchCV(my_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=5, n_jobs=-2, cv = cv)\n",
    "search.fit(X_train,y_train)\n",
    "print(abs(search.best_score_))\n",
    "search_pred = search.predict(X_valid)\n",
    "search_score = mean_absolute_error(y_valid, search_pred)\n",
    "print(search.best_params_)\n",
    "\n",
    "reg = ElasticNet(alpha=.253265, l1_ratio=0.66666666)\n",
    "my_pipe = Pipeline([(\"preprocessing\",preprocessing),\n",
    "                     (\"pca\", PCA(n_components = 42)),\n",
    "                     (\"reg\",reg)])\n",
    "my_pipe.fit(X_train, y_train)\n",
    "y_pred = my_pipe.predict(X_valid)\n",
    "score = mean_absolute_error(y_valid, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfr, lars, elnet, svr, ada, mlpr, xgbr = RandomForestRegressor(), LassoLars(), ElasticNet(), SVR(), AdaBoostRegressor(), MLPRegressor(), XGBRegressor()\n",
    "\n",
    "model_instances = [rfr, lars, elnet, svr, ada, mlpr, xgbr]\n",
    "rfr_list =[\"n_estimators\"]\n",
    "rfr_list.append(np.linspace(10, 200, 10, dtype=\"int\"))\n",
    "lars_list = [\"alpha\"]\n",
    "lars_list.append(np.linspace(.01, .2, 10))\n",
    "elnet = \n",
    "\n",
    "models = {}\n",
    "grids = []\n",
    "print(rfr_list)"
   ]
  }
 ]
}