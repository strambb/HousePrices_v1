{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, Pipeline and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partyequipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal stuff\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "#special effects\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lars, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partyguests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vspath\n",
    "path = r\"data\\train.csv\"\n",
    "X_raw = pd.read_csv(path, index_col=\"Id\")\n",
    "X_ana = X_raw.copy()\n",
    "X_test = pd.read_csv(path, index_col =\"Id\")\n",
    "print(X_raw.columns)\n",
    "\n",
    "#kaggle path\n",
    "#X_raw = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv', index_col='Id')\n",
    "#X_test = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv', index_col='Id')\n",
    "\n",
    "X = X_raw.copy()\n",
    "\n",
    "neighborhood_ordered = list(X.groupby(\"Neighborhood\")[\"SalePrice\"].mean().sort_values().index)\n",
    "\n",
    "X.dropna(subset=[\"SalePrice\"], axis=0, inplace=True)\n",
    "#X.dropna(axis=1, inplace = True)\n",
    "y = np.log(X.SalePrice)\n",
    "print(y)\n",
    "X.drop(\"SalePrice\", axis=1, inplace=True)\n",
    "\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "print(X.describe())\n",
    "\n",
    "X[\"MSSubClass\"] = X[\"MSSubClass\"].astype(\"category\")\n",
    "X_test[\"MSSubClass\"] = X_test[\"MSSubClass\"].astype(\"category\")\n",
    "\n",
    "col_obj = X.select_dtypes(include=[\"object\", \"bool\",\"category\"]).columns\n",
    "col_obj_above_10 = list([col for col in col_obj if X[col].nunique() > 15])\n",
    "col_obj_below_10 = list(set(col_obj)-set(col_obj_above_10))\n",
    "col_num = list(X.select_dtypes(exclude=[\"object\", \"bool\",\"category\"]).columns)\n",
    "col_with_nan = [col for col in X.columns if X[col].isna().any()]\n",
    "\n",
    "\n",
    "print(\"Summary:\\n\")\n",
    "print(\"Number of columns: {}\".format(len(X.columns)))\n",
    "print(\"Number of object columns: {}\".format(len(col_obj)))\n",
    "print(\"Number of columns with NaNs: {}\".format(len(col_with_nan)))\n",
    "print(\"Number of object columns with NaNs: {}\".format(len(set(col_with_nan)-set(col_num))))\n",
    "print(\"Number of numeric columns with NaNs: {}\".format(len(set(col_with_nan)-set(col_obj))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ordinal1:  \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\"\n",
    "#Ordinal2:  [\"BsmtFinType1\",\"BsmtFinType2\"]\n",
    "#Ordinal3: \"Electrical\"\n",
    "#Ordinal4: \n",
    "\n",
    "#numerical1:  LotFrontage\n",
    "\n",
    "for c in [\"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\",\"Electrical\",\"BsmtFinType1\",\"BsmtFinType2\"]:\n",
    "    col_obj_below_10.remove(c)\n",
    "    \n",
    "#col_obj_below_10.remove([\"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\",\"Electrical\",\"BsmtFinType1\",\"BsmtFinType2\"])\n",
    "\n",
    "\n",
    "X[\"LotFrontage\"]= X.groupby([\"LotShape\", \"LotConfig\",\"BldgType\"])[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "X_test[\"LotFrontage\"] = X.groupby([\"LotShape\", \"LotConfig\",\"BldgType\"])[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "log_cols = [\"GrLivArea\"]\n",
    "for c in log_cols:\n",
    "    X[c] = np.log(X[c].fillna(X[c].median()))\n",
    "    X_test[c]= np.log(X_test[c].fillna(X_test[c].median()))\n",
    "\n",
    "\n",
    "col_obj_below_10.append(\"MSSubClass\")\n",
    "col_num.remove(\"LotFrontage\")\n",
    "\n",
    "for c in  X.select_dtypes(include=[\"object\"]).columns:\n",
    "    X[c].fillna(\"None\")\n",
    "    X_test[c].fillna(\"None\")\n",
    "\n",
    "res= {}\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n[Parallel(n_jobs=-2)]: Done   1 tasks      | elapsed:    4.3s\n[Parallel(n_jobs=-2)]: Done   3 out of   3 | elapsed:    4.3s remaining:    0.0s\n[Parallel(n_jobs=-2)]: Done   3 out of   3 | elapsed:    4.3s finished\n-0.08444517040227473\n{'reg__alpha': 0.10925528556796542, 'reg__colsample_bytree': 0.5, 'reg__early_stopping_counts': 10, 'reg__gamma': 0, 'reg__learning_rate': 0.02428125, 'reg__max_depth': 5, 'reg__min_child_weight': 4, 'reg__n_estimators': 511, 'reg__subsample': 0.58}\n15073.62522295947\n"
    }
   ],
   "source": [
    "\n",
    "#reg = ElasticNet()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, train_size = 0.7, test_size=0.3, random_state=0)\n",
    "reg = XGBRegressor( evals=y_valid, eval_metric=\"mae\",cv=False, seed=0, verbosity=1 ) #evals=y_valid, eval_metric=\"mae\",\n",
    "\n",
    "\n",
    "#numeric_transformer = Pipeline([\"imputer\",SimpleImputer(strategy=\"median\")])\n",
    "\n",
    "#log y\n",
    "#y_train, y_valid = np.log(y_train), np.log(y_valid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#raising value error due to lack in synchronization caused by OneHotEncoder and OrdinalEncoder\n",
    "preprocessing = ColumnTransformer(transformers=[(\"numeric\", SimpleImputer(strategy = \"median\"), col_num) ,\n",
    "                                                (\"LotFrontage_\", SimpleImputer(strategy = \"median\"), [\"LotFrontage\"]) ,\n",
    "\n",
    "                                            (\"obj_below_10\", Pipeline([(\"obj_imputer1\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"OHE\"            , OneHotEncoder(handle_unknown='ignore'\n",
    "                                                                                                            ))\n",
    "                                                                        ]), col_obj_below_10) ,\n",
    "                                            (\"Neighborhood_\", Pipeline([(\"obj_imputer2\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder1\"  , OrdinalEncoder(categories=[neighborhood_ordered])\n",
    "                                                                                                            )\n",
    "                                                                        ]), [\"Neighborhood\"]),\n",
    "                                            (\"Ratings1_\", Pipeline([(\"obj_imputer3\", SimpleImputer(strategy =\"constant\", fill_value=\"TA\")),\n",
    "                                                                        (\"label_encoder2\"  , OrdinalEncoder(categories=[[\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "                                                                                                                        [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "                                                                                                                        [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "                                                                                                                        [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "                                                                                                                        [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]])\n",
    "                                                                                                            )\n",
    "                                                                        ]), [ \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\"]),\n",
    "                                            (\"Ratings2_\", Pipeline([(\"obj_imputer4\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder3\"  , OrdinalEncoder(categories=[[\"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NA\"],\n",
    "                                                                                                                        [\"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NA\"]])\n",
    "                                                                                                            )\n",
    "                                                                        ]), [\"BsmtFinType1\",\"BsmtFinType2\"]),\n",
    "                                            (\"Electric_\", Pipeline([(\"obj_imputer5\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoder4\"  , OrdinalEncoder(categories=[[\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"]])\n",
    "                                                                                                            )\n",
    "                                                                        ]), [\"Electrical\"]),\n",
    "                                            (\"Exterior_2nd\", Pipeline([(\"obj_imputer7\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "                                                                        (\"label_encoderX\"  , OrdinalEncoder(categories=[list(X[\"Exterior2nd\"].unique())]))\n",
    "                                                                        ]), [\"Exterior2nd\"])], remainder='drop')\n",
    "\n",
    "\n",
    "my_pipe = Pipeline([(\"preprocessing\",preprocessing),\n",
    "                     #(\"pca\", PCA(n_components = 35)),\n",
    "                     (\"rb_scaler\", RobustScaler()),\n",
    "                     (\"reg\",reg)])\n",
    "\n",
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": [31],\n",
    "                \"reg__early_stopping_counts\": [10],\n",
    "                \"reg__n_estimators\": [511],#done\n",
    "                \"reg__learning_rate\":[0.02428125],\n",
    "                \"reg__max_depth\": [5],#done\n",
    "                \"reg__min_child_weight\":[4],#done[1, 2, 3, 4, 5, 6, 7, 8], \n",
    "                \"reg__gamma\":[0], #done[ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "                \"reg__subsample\":[0.58],#done[0.940136255964662][0.3283798423145866]\n",
    "                \"reg__colsample_bytree\": [0.5], #done[i/100.0 for i in range(45,55,1)], \n",
    "                \"reg__alpha\":[0.10925528556796542], #done\n",
    "                \n",
    "                }\n",
    "\n",
    "\n",
    "cv = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search = GridSearchCV(my_pipe, param_grid=param_grid, scoring=\"neg_mean_absolute_error\", verbose=50, n_jobs=-2, cv = cv,)\n",
    "search.fit(X_train,y_train)\n",
    "print(search.best_score_)\n",
    "#print(\"best iteration: \", search.best_iteration, s)\n",
    "search_pred = search.predict(X_valid)\n",
    "#search_pred = np.exp(search_pred)\n",
    "search_score = mean_absolute_error(np.exp(y_valid), np.exp(search_pred))\n",
    "print(search.best_params_)\n",
    "#res[search.best_score_] = search.best_params_\n",
    "\n",
    "print(search_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('preprocessing',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('numeric',\n                                                  SimpleImputer(add_indicator=False,\n                                                                copy=True,\n                                                                fill_value=None,\n                                                                missing_values=nan,\n                                                                strategy='median',\n                                                                verbose=0),\n                                                  ['MSSubClass', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',...\n                              gamma=0, gpu_id=-1, importance_type='gain',\n                              interaction_constraints=None,\n                              learning_rate=0.02428125, max_delta_step=0,\n                              max_depth=5, min_child_weight=4, missing=nan,\n                              monotone_constraints=None, n_estimators=511,\n                              n_jobs=0, num_parallel_tree=1,\n                              objective='reg:squarederror', random_state=0,\n                              reg_alpha=0.109255284, reg_lambda=1,\n                              scale_pos_weight=1, seed=0, subsample=0.58, ...))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model = search.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": [31],\n",
    "                \"reg__early_stopping_counts\": [50],\n",
    "                \"reg__n_estimators\": [171],#done\n",
    "                \"reg__learning_rate\":[0.1],\n",
    "                \"reg__max_depth\": [4], #done[ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "                \"reg__min_child_weight\":[3], #done[1, 2, 3, 4, 5, 6, 7, 8], \n",
    "                \"reg__gamma\":[1], #done[ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "                \"reg__subsample\":[0.940136255964662],#done[0.940136255964662]\n",
    "                \"reg__colsample_bytree\": [0.5], #done[i/100.0 for i in range(45,55,1)], \n",
    "                \"reg__alpha\":[0.10925528556796542], #done\n",
    "                \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X_train.shape with outliers: (1460, 80)\nX_train.shape without outliers: (1428, 80)\n(1428, 79) (1459, 79)\n(2887, 79) \n\n# of Columns with NaNs: 34\nPoolQC          2880\nMiscFeature     2787\nAlley           2692\nFence           2322\nFireplaceQu     1412\nLotFrontage      479\nGarageFinish     153\nGarageYrBlt      153\nGarageQual       153\nGarageCond       153\nGarageType       151\nBsmtExposure      81\nBsmtCond          81\nBsmtQual          80\nBsmtFinType1      78\nBsmtFinType2      78\nMasVnrType        24\nMasVnrArea        23\nMSZoning           4\nBsmtFullBath       2\nBsmtHalfBath       2\nUtilities          2\nFunctional         2\nExterior2nd        1\nExterior1st        1\nSaleType           1\nBsmtFinSF1         1\nBsmtFinSF2         1\nBsmtUnfSF          1\nElectrical         1\nKitchenQual        1\nGarageCars         1\nGarageArea         1\nTotalBsmtSF        1\ndtype: int64\n# of Columns with NaNs: 0\n(2887, 86)\n(2887, 227)\nTrain and y have same lenght: True\n\n(1428, 220) \n (1459, 220) \n (1428,)\n14160.53097683567\n"
    }
   ],
   "source": [
    "#Load Modules\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax, boxcox\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#Definitons\n",
    "numeric_types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "#Load Data\n",
    "path = r\"data\\train.csv\"\n",
    "X_train = pd.read_csv(path, index_col= \"Id\")\n",
    "\n",
    "path = r\"data\\test.csv\"\n",
    "X_test = pd.read_csv(path, index_col= \"Id\")\n",
    "\n",
    "#Drop Id (if not useable)\n",
    "\n",
    "#Deletion of outliers (GrLiveArea>4500)\n",
    "print(\"X_train.shape with outliers: %s\" % str(X_train.shape))\n",
    "\n",
    "X_train = X_train[(X_train[\"LotFrontage\"] <=200) | X_train[\"LotFrontage\"].isna()]\n",
    "X_train = X_train[(X_train[\"LotArea\"] <= 75000)]\n",
    "X_train = X_train[(X_train[\"MasVnrArea\"] <=1400) | X_train[\"MasVnrArea\"].isna()]\n",
    "X_train = X_train[(X_train[\"BsmtFinSF1\"] <=2500)]\n",
    "X_train = X_train[(X_train[\"BsmtFinSF2\"] <=1200)]\n",
    "X_train = X_train[(X_train[\"TotalBsmtSF\"] <=3000)]\n",
    "X_train = X_train[(X_train[\"1stFlrSF\"] <=3000)]\n",
    "X_train = X_train[(X_train[\"2ndFlrSF\"] <=1750)]\n",
    "X_train = X_train[(X_train[\"GrLivArea\"] <=4500)]\n",
    "X_train = X_train[(X_train[\"BsmtFullBath\"] <=2)]\n",
    "X_train = X_train[(X_train[\"BsmtHalfBath\"] <=1)]\n",
    "X_train = X_train[(X_train[\"BedroomAbvGr\"] <=6)]\n",
    "X_train = X_train[(X_train[\"KitchenAbvGr\"] <=2)]\n",
    "X_train = X_train[(X_train[\"TotRmsAbvGrd\"] <=12) & (X_train[\"TotRmsAbvGrd\"] >=3)]\n",
    "X_train = X_train[(X_train[\"GarageArea\"] <=1300)]\n",
    "X_train = X_train[(X_train[\"WoodDeckSF\"] <=800)]\n",
    "X_train = X_train[(X_train[\"OpenPorchSF\"] <=500)]\n",
    "X_train = X_train[(X_train[\"EnclosedPorch\"] <=500)]\n",
    "X_train = X_train[(X_train[\"MiscVal\"] <=6000)]\n",
    "\n",
    "print(\"X_train.shape without outliers: {}\".format(X_train.shape))\n",
    "\n",
    "# Target transformation (log1p inplace)\n",
    "X_train[\"SalePrice\"] = np.log1p(X_train[\"SalePrice\"])\n",
    "\n",
    "# Save target in y, drop inX\n",
    "y = X_train[\"SalePrice\"]\n",
    "X_train.drop(\"SalePrice\", axis=1, inplace=True)\n",
    "\n",
    "#Concat Train + Test\n",
    "print(X_train.shape, X_test.shape)\n",
    "feat = pd.concat([X_train, X_test], ignore_index=True)\n",
    "print(feat.shape, \"\\n\")\n",
    "\n",
    "#Make non numerics which are categories stored as strings and vice versa\n",
    "num_to_str_cols = ['MSSubClass']\n",
    "#feat[num_to_str_cols] = feat[num_to_str_cols].apply(lambda x: str(x))\n",
    "for c in num_to_str_cols:\n",
    "    feat[c] = feat[c].apply(str)\n",
    "\n",
    "\n",
    "#Fill categoricals with logical values (medians) (per segment like Garage, Property, etc.)\n",
    "print(\"# of Columns with NaNs: {}\".format(len(feat.isna().sum()[feat.isna().sum() > 0])))\n",
    "print(feat.isna().sum()[feat.isna().sum() > 0].sort_values(ascending=False))\n",
    "\n",
    "feat[\"Alley\"] = feat[\"Alley\"].fillna(\"None\")\n",
    "feat[\"MasVnrType\"] = feat[\"MasVnrType\"].fillna(\"None\")\n",
    "feat[\"GarageYrBlt\"] = feat[\"GarageYrBlt\"].apply(lambda x: feat[\"YearBuilt\"].index[x.index] if x==None else x)\n",
    "\n",
    "#Fill other objects with mode and \"NA\"\n",
    "mode_fill_cols = [\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"Electrical\",\"FireplaceQu\",\"Functional\"]\n",
    "NA_fill_cols = [\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"PoolQC\",\"Fence\",\"MiscFeature\"]\n",
    "\n",
    "for c in mode_fill_cols:\n",
    "    feat[c] = feat[c].fillna(feat[c].mode()[0])\n",
    "\n",
    "for c in NA_fill_cols:\n",
    "    feat[c] = feat[c].fillna(\"NA\")\n",
    "\n",
    "#Fillthe rest with \"None\"\n",
    "for c in feat.select_dtypes(exclude=numeric_types):\n",
    "    feat[c] = feat[c].fillna(\"NA\")\n",
    "\n",
    "#Fill numerics with logical values (GrLivArea, LotFrontage)\n",
    "feat[\"LotFrontage\"]= feat.groupby([\"LotShape\", \"LotConfig\",\"BldgType\"])[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#Fill rest of nums with 0\n",
    "for c in feat.select_dtypes(include=numeric_types).columns:\n",
    "    feat[c] = feat[c].fillna(0)\n",
    "\n",
    "print(\"# of Columns with NaNs: {}\".format(len(feat.isna().sum()[feat.isna().sum() > 0])))\n",
    "#print(feat.isna().sum()[feat.isna().sum() > 0].sort_values(ascending=False))\n",
    "\n",
    "\n",
    "#reset index\n",
    "feat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Measure Skewness and save column names ### Data Leakage\n",
    "numeric_columns = feat.select_dtypes(include=numeric_types).columns\n",
    "\n",
    "feature_skewness = feat[numeric_columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "high_skewness = feature_skewness[abs(feature_skewness) > 0.5]\n",
    "skew_transform_index = high_skewness.index\n",
    "\n",
    "#Transform highly skewed to more normal\n",
    "for i in skew_transform_index:\n",
    "    feat[i] = boxcox1p(feat[i], boxcox_normmax(feat[i]+1)) #normmax method=\"all\"\n",
    "\n",
    "#Generate interessting (boosting) feature combinations (Yearbuild+remod, Porchsize, total sf, total rooms, total baths)\n",
    "feat[\"YearModBooster\"] = feat[\"YearBuilt\"] + feat[\"YearRemodAdd\"]\n",
    "feat[\"TotalHouseSize\"] = feat[\"TotalBsmtSF\"] + feat[\"1stFlrSF\"] + feat[\"2ndFlrSF\"]\n",
    "feat[\"TotalBath\"] = feat[\"FullBath\"] + 0.5 * feat[\"HalfBath\"]\n",
    "feat[\"PorchAreaSum\"] = feat[\"WoodDeckSF\"] + feat[\"OpenPorchSF\"] + feat[\"EnclosedPorch\"] + feat[\"3SsnPorch\"] + feat[\"ScreenPorch\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Create simplified statements (has pool, garage, 2ndfloor, basement, porch?)\n",
    "feat[\"HasBasement\"] = feat[\"TotalBsmtSF\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "feat[\"HasPool\"] = feat[\"PoolArea\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "feat[\"Has2nd\"] = feat[\"2ndFlrSF\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "feat[\"HasGarage\"] = feat[\"GarageArea\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "feat[\"HasPorch\"] = feat[\"PorchAreaSum\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "#Drop insignificant features (YrSold, MoSold)\n",
    "drop_cols = [\"YrSold\", \"MoSold\"]\n",
    "feat.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "#SpecialEncodings\n",
    "\n",
    "NAPoFaTAGdEx_cols = [\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\"HeatingQC\",\"KitchenQual\",\"FireplaceQu\",\"GarageQual\",\"GarageCond\",\"PoolQC\"]\n",
    "_OEncoder = OrdinalEncoder(categories = [[\"NA\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]]*len(NAPoFaTAGdEx_cols))\n",
    "feat[NAPoFaTAGdEx_cols] = pd.DataFrame(_OEncoder.fit_transform(feat[NAPoFaTAGdEx_cols].values ), columns=NAPoFaTAGdEx_cols, index=feat.index)\n",
    "\n",
    "Other_ordinal_cols = [\"BsmtExposure\", \"BsmtFinType1\",\"BsmtFinType2\", \"CentralAir\", \"Electrical\", \"Functional\", \"GarageFinish\", \"Fence\"]\n",
    "_OEncoder = OrdinalEncoder(categories = [[\"NA\",\"No\",\"Mn\",\"Av\",\"Gd\"],\n",
    "                                        [\"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NA\"],\n",
    "                                        [\"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NA\"],\n",
    "                                        [\"N\", \"Y\"],\n",
    "                                        [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"], \n",
    "                                        [\"Sal\", \"Sev\", \"Maj2\", \"Maj1\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "                                        [\"NA\", \"Unf\", \"RFn\", \"Fin\"],\n",
    "                                        [\"NA\", \"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"]] )\n",
    "\n",
    "feat[Other_ordinal_cols] = pd.DataFrame(_OEncoder.fit_transform(feat[Other_ordinal_cols].values ), columns=Other_ordinal_cols, index=feat.index)\n",
    "print(feat.shape)\n",
    "#mapper = {\"NA\" : 0, \"Po\":1, \"Fa\":2, \"TA\":3, \"Gd\":4, \"Ex\":5}\n",
    "#for c in NAPoFaTAGdEx_cols:\n",
    "\n",
    "#Get Dummies\n",
    "\n",
    "final_feat = pd.get_dummies(feat, drop_first=True).reset_index(drop=True)\n",
    "print(final_feat.shape)\n",
    "\n",
    "#Split in Train + test -> Train + Target\n",
    "X = final_feat.iloc[:len(y), :]\n",
    "X_test = final_feat.iloc[len(X):, :]\n",
    "\n",
    "print(\"Train and y have same lenght: {}\".format(len(X) == len(y)))\n",
    "\n",
    "#Drop overfitting columns of Train also in test\n",
    "print()\n",
    "\n",
    "Overfitter = []\n",
    "for c in X.columns:\n",
    "    zeros = len(X[X[c] == 0])\n",
    "    \n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        Overfitter.append(c)\n",
    "        \n",
    "#print(Overfitter)\n",
    "\n",
    "X = X.drop(Overfitter, axis=1).copy()\n",
    "X_test = X_test.drop(Overfitter, axis=1).copy()\n",
    "\n",
    "\n",
    "print(X.shape, \"\\n\", X_test.shape, \"\\n\", y.shape)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, train_size = 0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "XGBR_final = XGBRegressor(n_estimators=4500, learning_rate=0.008, max_depth = 4, min_child_weight=4, gamma=0, subsample= 0.940136255964662, colsample_bytree = 0.5, alpha = 0.10925528556796542, early_stopping_counts=50, evals=y_valid, eval_metric=\"mae\",cv=True, seed=0, verbosity=1 )\n",
    "\n",
    "\n",
    "my_pipe_out = Pipeline([#(\"preprocessing\", preprocessing),\n",
    "                        (\"rb_scaler\", RobustScaler()),\n",
    "                        (\"reg_final\", XGBR_final)\n",
    "                        ])\n",
    "\n",
    "\n",
    "my_pipe_out.fit(X_train, y_train)\n",
    "\n",
    "valid_preds = my_pipe_out.predict(X_valid)\n",
    "valid_score = mean_absolute_error(np.exp(y_valid), np.exp(valid_preds))\n",
    "print(valid_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "225\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = my_pipe_out.predict(X_test)\n",
    "\n",
    "#recalc preds\n",
    "test_preds=np.exp(test_preds)\n",
    "output = pd.DataFrame({\"Id\": X_test.index,\n",
    "                     \"SalePrice\": test_preds})\n",
    "output.to_csv(\"submission_other.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = {  #\"preprocessing__numeric__strategy\":[\"median\", \"mean\"],\n",
    "                #\"pca__n_components\": np.linspace(25, 65, 5, dtype=\"int\"),\n",
    "                \"reg__early_stopping_counts\": [50],\n",
    "                \"reg__n_estimators\": [342],\n",
    "                \"reg__learning_rate\":[0.04002371183530562],\n",
    "                \"reg__max_depth\": [5],\n",
    "                \"reg__min_child_weight\": [1.02],\n",
    "                \"reg__gamma\":[0],\n",
    "                \"reg__subsample\":[0.8264488486588846],\n",
    "                \"reg__colsample_bytree\": [0.551988011711525],\n",
    "                \"reg__alpha\":[0.107],\n",
    "                \n",
    "                }"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitdsproj10320conda7d2d0b8284c34340aa156a3daf2ddb47",
   "display_name": "Python 3.7.6 64-bit ('DS_proj1_03-20': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}